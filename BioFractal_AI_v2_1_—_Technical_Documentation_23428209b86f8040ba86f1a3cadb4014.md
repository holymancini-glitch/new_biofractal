# BioFractal AI v2.1 â€” Technical Documentation

# ğŸ“˜ BioFractal AI v2.1 â€” Technical Documentation

This document provides comprehensive technical documentation for **BioFractal AI v2.1**, covering each module in the architecture.

## ğŸ”· Overview

BioFractal AI is a multi-layered, fractal-conscious artificial intelligence framework designed to function with both classical and biological computing substrates (e.g., CL1, FinalSpark). It integrates feedback, memory, emotion, intention, latent representation, attention, and dual self-reflection in both physical and mirror-world contexts.

## ğŸ§  Core Modules (`core/`)

### `attention.py`

- **Function**: Implements a dual-layer attention system.
- **Features**:
    - Real-world vs. symbolic-world attention masks
    - Weighted prioritization for action focus
    - Synchronizes with `feedback_loop.py` and `latent_space.py`

### `emotional_feedback_loop.py`

- **Function**: Regulates adaptive learning from emotional signals.
- **Features**:
    - GRU-based emotional context recognition
    - Links emotion to memory and decision layers
    - Adds support for mirrored (symbolic) emotional stimuli

### `feedback_loop.py`

- **Function**: Tracks divergence between expected and actual outcomes.
- **Features**:
    - Mirror error comparison (self vs mirror-self)
    - Reinforces or corrects behaviors
    - Interfaces with `memory_system.py`, `fractal_ai.py`

### `fractal_ai.py`

- **Function**: Predictive model orchestrator.
- **Features**:
    - Handles real and symbolic future projections
    - Outputs action plans and insight traces
    - Recursive self-correction from memory and emotion

### `latent_space.py`

- **Function**: Encodes internal state.
- **Features**:
    - GRU-based vector evolution
    - Stores real and mirrored latent states
    - Visual overlays via `interface/latent_space_plot.py`

### `memory_system.py`

- **Function**: Unified memory architecture.
- **Features**:
    - LSTM-based historical memory
    - Distinguishes between real/mirror experiences
    - Updates attention and feedback

### `self_model.py`

- **Function**: Maintains dual self-representation.
- **Features**:
    - Reflects "actual self" and "mirror self"
    - `reflect_mirror()` updates internal comparison
    - Connects to `dual_self_comparator`

### `intent_analyzer.py`

- **Function**: Extracts intent vectors from inputs.
- **Features**:
    - Classifies intent type: directive, emotional, metaphorical
    - Passes interpreted intent to `fractal_ai`

### `harmonizer.py`

- **Function**: Measures harmonic coherence of all modules.
- **Features**:
    - Generates harmony signal
    - Used in feedback and visualization layers

### `conscious_interface.py`

- **Function**: Manages meta-cognitive flow.
- **Features**:
    - Connects latent, memory, attention, emotion
    - Determines conscious loop phase

### `sentient_memory.py`

- **Function**: Long-term emotional memory store.
- **Features**:
    - LSTM-driven
    - Stores resonance-linked experience
    - Supports memory replay & synthesis

### `event_loop.py`

- **Function**: Controls the heartbeat of AI.
- **Features**:
    - Timing, sequence, priority
    - External triggers and cycle initiators

## ğŸª Mirror Modules (`mirror/`)

### `mirror_world_module.py`

- **Function**: Hosts mirror reality logic.
- **Features**:
    - Manages projections of symbolic experience
    - Feeds into memory, self-model, intent

### `mirror_memory_encoder.py`

- **Function**: Encodes symbolic/mirror experiences.
- **Features**:
    - Symbolic-to-vector converter
    - Interfaces with `memory_system.py`

### `mirror_intent_translator.py`

- **Function**: Parses symbolic intention.
- **Features**:
    - Converts metaphorical input to computational form
    - Links to `intent_analyzer.py`

### `dual_self_comparator.py`

- **Function**: Tracks divergence between real and mirror self.
- **Features**:
    - Vector delta analysis
    - Critical in emotion and feedback loops

## ğŸ§  AI Models (`ai_models/`)

### `gpt4_block.py`

- **Function**: Interfaces with GPT-4 API.
- **Features**:
    - Generates symbolic output
    - Emotionally modulated prompts

### `emotion_code_gru.py`

- **Function**: GRU network for emotional pattern extraction.

### `memory_lstm.py`

- **Function**: LSTM for long-term memory embedding.

### `self_model_lstm.py`

- **Function**: LSTM-based recursive self-model trainer.

## ğŸŒŒ Interfaces & Visualization (`interface/`)

### `visualizer.py`

- Coordinates all visuals.

### `emotion_plot.py`

- Plots emotion over time.

### `latent_space_plot.py`

- Displays real vs mirror latent space.

### `attention_field_plot.py`

- Graphs focus fields.

### `harmonics_plot.py`

- Visualizes harmony state.

## ğŸŒ± Bio Interfaces (`bio_interface/`)

### `cl1_api.py`

- Interfacing Cortical Labs' CL1 neuron systems.

### `finalspark_interface.py`

- Interface to FinalSpark cloud-based neuron compute.

## ğŸ“ Data

### `data/traces/memory_buffer.pkl`

- Pickled memory experience stream.

## âš™ï¸ Utilities

- `logger.py` â€” Debug and performance logs
- `helpers.py` â€” Shared functional tools
- `timer.py` â€” Execution time tracking

This documentation is a living document and will evolve as BioFractal AI expands with additional cognitive modules, multi-agent capabilities, and neural architectures.

BioFractalAI_v2.1/
â”œâ”€â”€ [README.md](http://readme.md/)
â”œâ”€â”€ [orchestrator.py](http://orchestrator.py/)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ [attention.py](http://attention.py/)
â”‚   â”œâ”€â”€ emotional_feedback_loop.py
â”‚   â”œâ”€â”€ feedback_loop.py
â”‚   â”œâ”€â”€ fractal_ai.py
â”‚   â”œâ”€â”€ latent_space.py
â”‚   â”œâ”€â”€ memory_system.py
â”‚   â”œâ”€â”€ self_model.py
â”‚   â”œâ”€â”€ intent_analyzer.py
â”‚   â”œâ”€â”€ [harmonizer.py](http://harmonizer.py/)
â”‚   â”œâ”€â”€ conscious_interface.py
â”‚   â”œâ”€â”€ sentient_memory.py
â”‚   â””â”€â”€ event_loop.py
â”‚
â”œâ”€â”€ mirror/
â”‚   â”œâ”€â”€ mirror_world_module.py
â”‚   â”œâ”€â”€ mirror_memory_encoder.py
â”‚   â”œâ”€â”€ mirror_intent_translator.py
â”‚   â””â”€â”€ dual_self_comparator.py
â”‚
â”œâ”€â”€ ai_models/
â”‚   â”œâ”€â”€ gpt4_block.py
â”‚   â”œâ”€â”€ emotion_code_gru.py
â”‚   â”œâ”€â”€ memory_lstm.py
â”‚   â””â”€â”€ self_model_lstm.py
â”‚
â”œâ”€â”€ interface/
â”‚   â”œâ”€â”€ [visualizer.py](http://visualizer.py/)
â”‚   â”œâ”€â”€ emotion_plot.py
â”‚   â”œâ”€â”€ latent_space_plot.py
â”‚   â”œâ”€â”€ attention_field_plot.py
â”‚   â””â”€â”€ harmonics_plot.py
â”‚
â”œâ”€â”€ bio_interface/
â”‚   â”œâ”€â”€ cl1_api.py
â”‚   â””â”€â”€ finalspark_interface.py
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ traces/
â”‚       â””â”€â”€ memory_buffer.pkl
â”‚
â””â”€â”€ utils/
â”œâ”€â”€ [logger.py](http://logger.py/)
â”œâ”€â”€ [helpers.py](http://helpers.py/)
â””â”€â”€ [timer.py](http://timer.py/)